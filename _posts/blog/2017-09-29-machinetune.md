---
layout: post
title: 机器学习优化策略
categories: Blog
description: 机器学习
keywords: 机器学习 优化策略
---

# 评估方法
 通常我们可通过实验验证来对学习器的泛华误差进行评估并进而做出选择，为此，我们需要一个测试集，通常，我们假设测试样本也是从样本真实分布中独立同分布采样而得，但需要注意的是，测试集应该尽可能与训练集互斥，即测试样本尽量不在训练集中出现，未在训练过程中使用过。

 可是我们是有一个包含m个样例的数据集，既要训练，又要测试，怎么做？答案是：通过对D进行适当的处理，从中产生出训练集S和测试集T。下面是集中常见的做法。

## 留出法
留出法直接将数据集D划分为两个互斥的集合，一个做训练集S，另一个作为测试集T。

需要注意的是，训练/测试集的划分要尽可能保持数据分布的一致性，避免数据划分过程引入的额外的偏差而对最终结果产生影响，例如在分类任务中至少要保证样本的类别比例相似。

另一个需要注意的问题是，即便在给定训练/测试集的样本比例后，仍存在多种划分方式对初始数据集D进行分割，不同的划分相应的模型评估的结果也会有差别，因此，单次使用留出法得到的估计结果往往不够稳定可靠，在使用留出法时，一般要采用若干次随机划分、重复进行实验评估后取平均值作为留出法的评估结果。

常见做法是将大约3/4~4/5的样本用于训练，剩余样本用于测试。

## 交叉验证法

交叉验证先将数据集D划分为k个大小相似的互斥子集，每个子集尽可能保持数据分布的一致性，即从D中通过分层采样得到。然后，每次用k-1个子集作为训练集，余下的那个子集作为测试集，这样就可获得k组训练/测试集，从而可进行k次训练和测试，最终返回的是这k个测试结果的均值。

k最常用的取值是10，其他常用的k值有5、20等。

当只有m个样本，且k=m时，称为：留一法。

## 自助法

给定包含m个样本的数据集D，我们对它进行采样尝试数据集D':每次随机从D中挑选一个样本，将其拷贝放入D‘，然后再将该样本放回初始数据集D中，使得该样本在下次采样时仍有可能被采到，这个过程重复执行m次后，我们就得到了包含m个样本的数据集D'，这就是自助采样的结果。

通过自助采样，初始数据集D中约有36.8%的样本未出现在采样数据集D'中，于是我们可将D'用作训练集，D\D’用作测试集，亦称为“包外估计”。

自助法在数据集较小、难以有效划分训练/测试集时很有用；此外，自助法能从初始数据集中产生多个不同的训练集，这对集成学习等方法有很大的好处，然而，自助法产生的数据集改变了初始数据集的分布，这会引入估计偏差。因此，在初始数据量足够时，留出法和交叉验证法更常用一些。


